{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nerf_colab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FtjuySytsiD"
      },
      "source": [
        "# Installation (only required for the first run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjDZ_CNzoncH"
      },
      "source": [
        "!git clone --recursive https://github.com/kwea123/nerf_pl\n",
        "\n",
        "%cd /content/nerf_pl\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "%cd /content/nerf_pl/torchsearchsorted\n",
        "!pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWJIcY5_t2Cl"
      },
      "source": [
        "# Mount your google drive (to access data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7qlz9AlqpjE",
        "outputId": "5c383b83-e6c9-4155-90eb-1f20b5835ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC4P161it9bb"
      },
      "source": [
        "# Train! (depending on number of epochs, takes about 5~8 hours)\n",
        "\n",
        "### model weights are saved to `ckpts/$EXP`\n",
        "### training logs (loss/PSNR evolution) are saved to `logs/$EXP`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR-o1P3cyiKS"
      },
      "source": [
        "## Forward facing scene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35_YDDErL6T",
        "outputId": "7b74f894-544d-496a-cb12-996636ae8187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "%cd /content/nerf_pl\n",
        "\n",
        "import os\n",
        "# set training configurations here\n",
        "os.environ['ROOT_DIR'] = \"/content/drive/My Drive/colab/nerf/nerf_llff_data/fern\"\n",
        "                         # directory containing the data\n",
        "os.environ['IMG_W'] = \"504\" # image width (do not set too large)\n",
        "os.environ['IMG_H'] = \"378\" # image height (do not set too large)\n",
        "os.environ['NUM_EPOCHS'] = \"30\" # number of epochs to train (depending on how many images there are,\n",
        "                                # 20~30 might be enough)\n",
        "os.environ['EXP'] = \"fern\" # name of the experience (arbitrary)\n",
        "\n",
        "!python train.py \\\n",
        "   --dataset_name llff \\\n",
        "   --root_dir \"$ROOT_DIR\" \\\n",
        "   --N_importance 64 --img_wh $IMG_W $IMG_H \\\n",
        "   --num_epochs $NUM_EPOCHS --batch_size 1024 \\\n",
        "   --optimizer adam --lr 5e-4 \\\n",
        "   --lr_scheduler cosine \\\n",
        "   --exp_name $EXP"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/nerf_pl\n",
            "INFO:lightning:GPU available: True, used: True\n",
            "INFO:lightning:VISIBLE GPUS: 0\n",
            "val image is /content/drive/My Drive/colab/nerf/nerf_llff_data/fern/images/IMG_4038.JPG\n",
            "2020-04-26 09:16:47.901672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Epoch 1: 100% 3535/3536 [11:00<00:00,  5.35it/s, loss=0.014, train_psnr=22.2, v_num=0]\n",
            "Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1: 100% 3536/3536 [11:11<00:00,  5.27it/s, loss=0.014, train_psnr=22.2, v_num=0, val_loss=0.0149, val_psnr=21.3]\n",
            "Epoch 2: 100% 3535/3536 [10:59<00:00,  5.36it/s, loss=0.012, train_psnr=22.5, v_num=0, val_loss=0.0149, val_psnr=21.3]\n",
            "Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2: 100% 3536/3536 [11:10<00:00,  5.28it/s, loss=0.012, train_psnr=22.5, v_num=0, val_loss=0.0125, val_psnr=22.1]\n",
            "Epoch 3: 100% 3535/3536 [11:02<00:00,  5.34it/s, loss=0.010, train_psnr=23.3, v_num=0, val_loss=0.0125, val_psnr=22.1]\n",
            "Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3: 100% 3536/3536 [11:13<00:00,  5.25it/s, loss=0.010, train_psnr=23.3, v_num=0, val_loss=0.011, val_psnr=22.6] \n",
            "Epoch 4: 100% 3535/3536 [11:02<00:00,  5.33it/s, loss=0.010, train_psnr=22.8, v_num=0, val_loss=0.011, val_psnr=22.6]\n",
            "Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4: 100% 3536/3536 [11:14<00:00,  5.25it/s, loss=0.010, train_psnr=22.8, v_num=0, val_loss=0.0104, val_psnr=22.9]\n",
            "Epoch 5: 100% 3535/3536 [11:02<00:00,  5.33it/s, loss=0.009, train_psnr=23.6, v_num=0, val_loss=0.0104, val_psnr=22.9]\n",
            "Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5: 100% 3536/3536 [11:13<00:00,  5.25it/s, loss=0.009, train_psnr=23.6, v_num=0, val_loss=0.00984, val_psnr=23.2]\n",
            "Epoch 6:   1% 21/3536 [00:04<12:19,  4.75it/s, loss=0.009, train_psnr=24.1, v_num=0, val_loss=0.00984, val_psnr=23.2]INFO:lightning:Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "Epoch 6:   1% 21/3536 [00:04<12:48,  4.57it/s, loss=0.009, train_psnr=24.1, v_num=0, val_loss=0.00984, val_psnr=23.2]\n",
            "INFO:lightning:\n",
            "\n",
            "Profiler Report\n",
            "\n",
            "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
            "-----------------------------------------------------------------\n",
            "on_train_start      \t|  1.9846e-05     \t|  1.9846e-05     \n",
            "on_epoch_start      \t|  9.1695e-06     \t|  5.5017e-05     \n",
            "get_train_batch     \t|  0.00042811     \t|  7.5784         \n",
            "on_batch_start      \t|  9.6239e-06     \t|  0.17031        \n",
            "model_forward       \t|  0.057772       \t|  1022.4         \n",
            "model_backward      \t|  0.080761       \t|  1429.1         \n",
            "on_after_backward   \t|  3.6579e-06     \t|  0.064729       \n",
            "optimizer_step      \t|  0.0049311      \t|  87.262         \n",
            "on_batch_end        \t|  9.5256e-06     \t|  0.16857        \n",
            "on_epoch_end        \t|  7.7046e-06     \t|  3.8523e-05     \n",
            "on_train_end        \t|  2.1417e-05     \t|  2.1417e-05     \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jk8eHzM91td"
      },
      "source": [
        "## 360 inward-facing scene"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHSCPvKGsevy"
      },
      "source": [
        "%cd /content/nerf_pl\n",
        "\n",
        "import os\n",
        "# set training configurations here\n",
        "os.environ['ROOT_DIR'] = \"set your directory!\"\n",
        "                         # directory containing the data\n",
        "os.environ['IMG_W'] = \"504\" # image width (do not set too large)\n",
        "os.environ['IMG_H'] = \"378\" # image height (do not set too large)\n",
        "os.environ['NUM_EPOCHS'] = \"30\" # number of epochs to train (depending on how many images there are,\n",
        "                                # 20~30 might be enough)\n",
        "os.environ['EXP'] = \"exp\" # name of the experience (arbitrary)\n",
        "\n",
        "!python train.py \\\n",
        "   --dataset_name llff \\\n",
        "   --root_dir \"$ROOT_DIR\" \\\n",
        "   --N_importance 64 --img_wh $IMG_W $IMG_H \\\n",
        "   --spheric --use_disp \\\n",
        "   --num_epochs $NUM_EPOCHS --batch_size 1024 \\\n",
        "   --optimizer adam --lr 5e-4 \\\n",
        "   --lr_scheduler cosine \\\n",
        "   --exp_name $EXP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ziFoDza-kFT"
      },
      "source": [
        "# Testing! (takes about 20~30 minutes)\n",
        "\n",
        "### You can also download the pretrained model for `fern` [here](https://github.com/kwea123/nerf_pl/releases)\n",
        "\n",
        "### The results are saved to `results/llff/$SCENE`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuEZAYk0-k4j",
        "outputId": "db46357a-fce0-4102-c562-2e62c9ef9bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.environ['SCENE'] = 'fern'\n",
        "os.environ['CKPT_PATH'] = '/content/epoch.40.ckpt'\n",
        "\n",
        "!python eval.py \\\n",
        "   --root_dir \"$ROOT_DIR\" \\\n",
        "   --dataset_name llff --scene_name $SCENE \\\n",
        "   --img_wh $IMG_W $IMG_H --N_importance 64 --ckpt_path $CKPT_PATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 120/120 [20:48<00:00, 10.41s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}